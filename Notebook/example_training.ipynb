{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to set up Rivanna GPU to train Deep_iSith and LSTM models\n",
    "### 1. Use  PyTorch 1.4.0 Py3.7 Kernal/ Container on Rivanna\n",
    "Try to use V100 GPU, since it is much faster than the others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. pip install the necessary packages and download the [SITH_Layer_master] folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user mne\n",
    "#!pip install --user seaborn\n",
    "#### pytorch and Cuda should be set up correctly on the Pytorch kernal or pytorch container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run the code interactively in JupyterLab or by command line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.1 Use the following script: model parameters controlled by config/training_config.ini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarting to load Subject1 Data.\n",
      "Finished! 8 data are loaded and preprocessed\n",
      "torch.Size([26, 32, 50000]) torch.Size([26, 6, 50000])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be78a38def144b27aa681a74fc03c6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5c29d7432bfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mperf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     perf = train_model(model, ttype, train_loader, val_loader,\n\u001b[0;32m--> 127\u001b[0;31m                     optimizer, loss_func, epochs=nepochs)\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sfs/qumulo/qhome/yw9et/Sith_capstone/train_util.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, ttype, train_loader, val_loader, optimizer, loss_func, epochs, loss_buffer_size, prog_bar)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;31m#--- Record name, loss, validation accuracy --#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mloss_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mloss_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mloss_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\"\"\"\n",
    "3.1\n",
    "General-purpose training script for Grasp-and-lift EEG data prediction and classification\n",
    "Currently support:\n",
    "1. A base model for LSTM (Rivanna GPU)\n",
    "2. Deep_isith module\n",
    "**Use Kernal PyTorch 1.4.0 Py3.7**  \n",
    "parts are from **Neural Network Example**(Authors: Brandon G. Jacques and Per B. Sederberg)\n",
    "\n",
    "Yibo Wang\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from train_util import *\n",
    "from Deep_isith_EEG import *\n",
    "from base_models import *\n",
    "import pandas as pd\n",
    "# read config file\n",
    "import configparser\n",
    "import argparse\n",
    "\n",
    "# enable use of command line\n",
    "parser = argparse.ArgumentParser(description='Input config files')\n",
    "parser.add_argument('--config', default = 'config/training_config_Deep_isith.ini', type=str,\n",
    "                    help='an integer for the accumulator')\n",
    "opt, _ = parser.parse_known_args()\n",
    "\n",
    "# parser to read parameters\n",
    "config = configparser.ConfigParser()\n",
    "config.sections()\n",
    "\n",
    "# parameters from config file\n",
    "results = []\n",
    "config.read(opt.config)\n",
    "dir = config['data']['directory']\n",
    "subject_num = int(config['data']['subject #'])\n",
    "kernel_size = int(config['training']['kernel_size'])# sliding window size to use\n",
    "step = int(config['training']['step']) #  --the step between each slice. means overlap between batches is 1- step \n",
    "modelName = config['training']['model']\n",
    "# num of epochs to train\n",
    "nepochs = int(config['training']['nepochs'])\n",
    "loss_func =  torch.nn.CrossEntropyLoss()\n",
    "batch_size = int(config['training']['batch_size']) # batch_size is a hyper parameter to tune \n",
    "train_split = float(config['training']['train_split'])\n",
    "lr = float(config['training']['lr'])\n",
    "\n",
    "# load data and do preprocessing\n",
    "train_x_list = []\n",
    "train_y_list = []\n",
    "print(f\"Sarting to load Subject{subject_num} Data.\")\n",
    "for file in os.listdir(dir):\n",
    "    sub_idx = file.find('_')\n",
    "    if file[:-4].endswith('_data') & (file[4:sub_idx] == str(subject_num)):\n",
    "        raw = creat_mne_raw_object(dir+file,read_events=True)\n",
    "        # filter all channels\n",
    "        input_signal,target_signal = filter_standardization(raw,window_size = 1000,\n",
    "                            l_freq = 0,h_freq = 30)\n",
    "\n",
    "        input_tensor = ttype(input_signal.reshape(1,1,input_signal.shape[0],-1))\n",
    "        target_tensor = labeltype(target_signal.reshape(6,-1)) # should be six channels\n",
    "        input_tensor = input_tensor.squeeze()\n",
    "        # patches data \n",
    "        patches_train = input_tensor.unfold(dimension = 1, size = kernel_size, step = step).permute(1,0,2)\n",
    "        patches_label = target_tensor.unfold(1, kernel_size, step).permute(1,0,2)\n",
    "        #print(patches_train.shape, patches_label.shape)\n",
    "\n",
    "        # append to a list\n",
    "        train_x_list.append(patches_train)\n",
    "        train_y_list.append(patches_label)  \n",
    "print(\"Finished! {} data are loaded and preprocessed\".format(len(train_x_list)))\n",
    "\n",
    "# concatenate them\n",
    "train_x_t = torch.cat(train_x_list, dim=0)\n",
    "train_y_t = torch.cat(train_y_list, dim=0)\n",
    "print(train_x_t.shape, train_y_t.shape)\n",
    "\n",
    "# start training, iterate thorugh events\n",
    "for i in range(1,7): # There are six events 1 - 6\n",
    "    nClass = i - 1\n",
    "    train_y_t_nClass = train_y_t[:,nClass,:]\n",
    "    # create dataloader class\n",
    "    train_loader,val_loader = split_train_val(train_x_t ,train_y_t_nClass,\n",
    "                    batch_size = batch_size, train_split = train_split)\n",
    "\n",
    "    # match with modelsm currently model name has to be exact\n",
    "    if modelName == 'Deep_isith':\n",
    "        #--------------- sith layer model parameters ------------------#\n",
    "        # make sure this in_features matches the number of feutures in the EEG data\n",
    "        sith_params1 = {\"in_features\":32, \n",
    "                        \"tau_min\":1, \"tau_max\":150, \n",
    "                        \"k\":15, 'dt':1,\n",
    "                        \"ntau\":8, 'g':0.0,  \n",
    "                        \"ttype\":ttype, \n",
    "                        \"hidden_size\":25, \"act_func\":nn.ReLU()}\n",
    "\n",
    "        sith_params2 = {\"in_features\":sith_params1['hidden_size'], \n",
    "                        \"tau_min\":1, \"tau_max\":150.0, 'buff_max':600, \n",
    "                        \"k\":4, 'dt':1,\n",
    "                        \"ntau\":8, 'g':0.0, \n",
    "                        \"ttype\":ttype, \n",
    "                        \"hidden_size\":25, \"act_func\":nn.ReLU()}\n",
    "        layer_params = [sith_params1, sith_params2]\n",
    "\n",
    "        #------------------ model configuration ------------------------#\n",
    "        # number of output feature should be 2 since we always train one at a time, so now 1+1\n",
    "        model = DeepSITH_Tracker(out=2,\n",
    "                                    layer_params=layer_params, \n",
    "                                    dropout=0.1).double()\n",
    "    elif modelName == 'LSTM':\n",
    "        hidden_size = 50 # try 256  later\n",
    "        # make sure this in_features matches the number of feutures in the EEG data\n",
    "        model = LSTM_EEG(in_features = 32, hidden_dim = hidden_size, \n",
    "                          out_feuture = 2,num_layers =3, dropout=0.1).double()\n",
    "    else:\n",
    "        print('Model name not recognized!')\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    # map model to GPU\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    #------------------- start training ---------------------------#\n",
    "    perf = []\n",
    "    perf = train_model(model, ttype, train_loader, val_loader,\n",
    "                    optimizer, loss_func, epochs=nepochs)\n",
    "    results.append(perf)\n",
    "\n",
    "\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    PATH = f'./models/{modelName}_Subject{str(subject_num)}_numEvent{nClass}.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n",
    "# save results\n",
    "df = pd.DataFrame()\n",
    "event = ['HandStart','FirstDigitTouch','BothStartLoadPhase',\n",
    "            'LiftOff','Replace','BothReleased']\n",
    "for i in range(len(results)):\n",
    "    perf = results[i]\n",
    "    new_df = pd.DataFrame(perf)\n",
    "    new_df['event'] = event[i]\n",
    "    df = df.append(new_df)\n",
    "if not os.path.exists('csv'):\n",
    "    os.makedirs('csv')\n",
    "csv_name = f'./csv/{modelName}_Subject{str(subject_num)}.csv'\n",
    "df.to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.2  \n",
    "        Use the --config file to specify training parameters.  \n",
    "        Can also be used to specify model used to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command line\n",
    "# Run in Jupyter notebook/LAb, can be very slow\n",
    "# !python train.py --config ./config/training_config_LSTM.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use the train_all.py  \n",
    "### Submit SLURM job to train on Rivanna.  \n",
    "### need to first copy the pytorch-1.4.0-py37.sif container to Desktop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit SLURM job to train on Rivanna\n",
    "# need to first copy the pytorch-1.4.0-py37.sif container to Desktop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH -o deep_isith.out\n",
    "\n",
    "#SBATCH -e deep_isith.err\n",
    "\n",
    "#SBATCH -p gpu\n",
    "\n",
    "#SBATCH --gres=gpu:v100:1\n",
    "\n",
    "#SBATCH --mem=32000\n",
    "\n",
    "#SBATCH -t 36:00:00\n",
    "\n",
    "#SBATCH -A uva-dsi-msds\n",
    "\n",
    "module load singularity\n",
    "\n",
    "singularity run --nv /home/$USER/pytorch-1.4.0-py37.sif train_all.py --config ./config/training_config_Deep_isith.ini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.4.0 Py3.7",
   "language": "python",
   "name": "pytorch140_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
