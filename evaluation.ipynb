{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Deep_iSith and LSTM models on the holdout set\n",
    "Four metrics are computed for both models. columnwise AUC, Precision, Recall and F1.   \n",
    "Use  PyTorch 1.4.0 Py3.7 Kernal/ Container on Rivanna   \n",
    "Try to use V100 GPU, since it is much faster than the others   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pip install the necessary packages and download the [SITH_Layer_master] folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user mne\n",
    "#!pip install --user seaborn\n",
    "#### pytorch and Cuda should be set up correctly on the Pytorch kernal or pytorch container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep_SITH parameters and architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.DoubleTensor'>\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.eval import evaluation\n",
    "from src.train_util import *\n",
    "from models.Deep_isith_EEG_model import *\n",
    "from models.LSTM_EEG_model import *\n",
    "\n",
    "# read config file\n",
    "import configparser\n",
    "import argparse\n",
    "\n",
    "# preprocessing\n",
    "import mne\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "ttype = torch.cuda.DoubleTensor if torch.cuda.is_available() else torch.DoubleTensor\n",
    "labeltype = torch.cuda.LongTensor if torch.cuda.is_available() else torch.LongTensor\n",
    "print(ttype)\n",
    "from torch.utils.data import Dataset,DataLoader \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# training \n",
    "from torch import nn as nn\n",
    "from math import factorial\n",
    "import random\n",
    "import seaborn as sn\n",
    "import os \n",
    "from os.path import join\n",
    "import glob\n",
    "\n",
    "# validation\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, matthews_corrcoef,confusion_matrix,plot_roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSITH_Tracker(\n",
       "  (hs): DeepSITH(\n",
       "    (layers): ModuleList(\n",
       "      (0): _DeepSITH_core(\n",
       "        (sith): iSITH(ntau=10, tau_min=1, tau_max=50, buff_max=150, dt=1, k=23, g=0.0)\n",
       "        (linear): Linear(in_features=320, out_features=20, bias=True)\n",
       "        (dense_bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act_func): ReLU()\n",
       "      )\n",
       "      (1): _DeepSITH_core(\n",
       "        (sith): iSITH(ntau=10, tau_min=1, tau_max=200.0, buff_max=600.0, dt=1, k=12, g=0.0)\n",
       "        (linear): Linear(in_features=200, out_features=20, bias=True)\n",
       "        (dense_bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act_func): ReLU()\n",
       "      )\n",
       "      (2): _DeepSITH_core(\n",
       "        (sith): iSITH(ntau=10, tau_min=1, tau_max=800.0, buff_max=2400.0, dt=1, k=7, g=0.0)\n",
       "        (linear): Linear(in_features=200, out_features=20, bias=True)\n",
       "        (dense_bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act_func): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (dropouts): ModuleList(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (to_out): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sith_params1 = {\"in_features\":32, \n",
    "                        \"tau_min\":1, \"tau_max\":50, \n",
    "                        \"k\":23, 'dt':1,\n",
    "                        \"ntau\":10, 'g':0.0,  \n",
    "                        \"ttype\":ttype, \n",
    "                        \"hidden_size\":20, \"act_func\":nn.ReLU()}\n",
    "\n",
    "sith_params2 = {\"in_features\":sith_params1['hidden_size'], \n",
    "                        \"tau_min\":1, \"tau_max\":200.0,  \n",
    "                        \"k\":12, 'dt':1,\n",
    "                        \"ntau\":10, 'g':0.0, \n",
    "                        \"ttype\":ttype, \n",
    "                        \"hidden_size\":20, \"act_func\":nn.ReLU()}\n",
    "sith_params3 = {\"in_features\":sith_params2['hidden_size'], \n",
    "                    \"tau_min\":1, \"tau_max\":800.0,  \n",
    "                    \"k\":7, 'dt':1,\n",
    "                    \"ntau\":10, 'g':0.0, \n",
    "                    \"ttype\":ttype, \n",
    "                    \"hidden_size\":20, \"act_func\":nn.ReLU()}\n",
    "layer_params = [sith_params1, sith_params2,sith_params3]\n",
    "\n",
    "file = 'Deep_isith_Subject2_numEvent0.pth'\n",
    "PATH = 'saved_NNs/' + file\n",
    "model1 = DeepSITH_Tracker(out=2,\n",
    "                         layer_params=layer_params, dropout=0.1).double()\n",
    "model1.load_state_dict(torch.load(PATH))\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of parameters for Deep_isith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_weights 14622\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "for p in model1.parameters():\n",
    "    tot += p.numel()\n",
    "print(\"tot_weights\", tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM parameters and architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_weights 16352\n",
      "LSTM_EEG(\n",
      "  (lstm): LSTM(32, 25, num_layers=3, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=25, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# number of parameters \n",
    "hidden_size = 25\n",
    "model2 = LSTM_EEG(in_features = 32, hidden_dim = hidden_size, \n",
    "                          out_feuture = 2,num_layers =3, dropout=0.1).double()\n",
    "tot = 0\n",
    "for p in model2.parameters():\n",
    "    tot += p.numel()\n",
    "print(\"tot_weights\", tot)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate all subjects for DeepSITH and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, val_loader):\n",
    "    \"\"\"\n",
    "    Test for accuracy\n",
    "    Iterate through each batch and make prediciton and calculate performance metrics\n",
    "    Use **matthews correlation coeefficient** since the data are imbanlanced\n",
    "    Again \n",
    "    Signals need to be in correct format. validation input: [nbatch x 1 x nFeutures x time] tensor.\n",
    "\n",
    "    The target has dimension of [time] tensor, in which each entry should be one of the numbers in \n",
    "    {0,1,2, ... K} at any time point.  \n",
    "    \n",
    "    \"\"\"\n",
    "    inferenced_y = np.empty(0)\n",
    "    ground_truth_y = np.empty(0)\n",
    "    for _, (val_x, labels) in enumerate(val_loader):\n",
    "        out_val = model(val_x)\n",
    "        #print(out_val.shape)\n",
    "        # pass through a softmax to tansform to probability on the third dimention (nbatch, seq, outFeature)\n",
    "        res = torch.nn.functional.softmax(out_val, dim=2)\n",
    "        #print(res.shape)\n",
    "        # predict should also be the second dimension [1] to clauclate AUC\n",
    "        y_pred = res[:,:,1]\n",
    "\n",
    "        # flatten the predicted result \n",
    "        y_score = np.ndarray.flatten(y_pred.detach().cpu().numpy())\n",
    "\n",
    "        # flatten the predicted result \n",
    "        y_true = np.ndarray.flatten(labels.detach().cpu().numpy())\n",
    "        \n",
    "        inferenced_y = np.concatenate((inferenced_y, y_score), axis=0)\n",
    "        ground_truth_y = np.concatenate((ground_truth_y, y_true), axis=0)\n",
    "    return inferenced_y,ground_truth_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sith parameters. Have to be exact as training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sith_params1 = {\"in_features\":32, \n",
    "                        \"tau_min\":1, \"tau_max\":50, \n",
    "                        \"k\":23, 'dt':1,\n",
    "                        \"ntau\":10, 'g':0.0,  \n",
    "                        \"ttype\":ttype, \n",
    "                        \"hidden_size\":20, \"act_func\":nn.ReLU()}\n",
    "\n",
    "sith_params2 = {\"in_features\":sith_params1['hidden_size'], \n",
    "                        \"tau_min\":1, \"tau_max\":200.0,  \n",
    "                        \"k\":12, 'dt':1,\n",
    "                        \"ntau\":10, 'g':0.0, \n",
    "                        \"ttype\":ttype, \n",
    "                        \"hidden_size\":20, \"act_func\":nn.ReLU()}\n",
    "sith_params3 = {\"in_features\":sith_params2['hidden_size'], \n",
    "                    \"tau_min\":1, \"tau_max\":800.0,  \n",
    "                    \"k\":7, 'dt':1,\n",
    "                    \"ntau\":10, 'g':0.0, \n",
    "                    \"ttype\":ttype, \n",
    "                    \"hidden_size\":20, \"act_func\":nn.ReLU()}\n",
    "layer_params = [sith_params1, sith_params2,sith_params3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference_all function. Specify which model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_all(model = 'DeepSITH'):\n",
    "    # enable use of command line\n",
    "    parser = argparse.ArgumentParser(description='Input config files')\n",
    "    parser.add_argument('--config', default = 'config/training_config_Deep_isith.ini', type=str,\n",
    "                        help='an integer for the accumulator')\n",
    "    opt, _ = parser.parse_known_args()\n",
    "\n",
    "    # parser to read parameters\n",
    "    config = configparser.ConfigParser()\n",
    "    config.sections()\n",
    "\n",
    "    # parameters from config file\n",
    "    results = []\n",
    "    config.read(opt.config)\n",
    "    dir = config['data']['directory']\n",
    "    subject_num = int(config['data']['subject #'])\n",
    "    kernel_size = int(config['training']['kernel_size'])# sliding window size to use\n",
    "    step = int(config['training']['step']) #  --the step between each slice. means overlap between batches is 1- step \n",
    "    modelName = config['training']['model']\n",
    "    # num of epochs to train\n",
    "    nepochs = int(config['training']['nepochs'])\n",
    "    loss_func =  torch.nn.CrossEntropyLoss()\n",
    "    batch_size = int(config['training']['batch_size']) # batch_size is a hyper parameter to tune \n",
    "    #train_split = float(config['training']['train_split'])\n",
    "    lr = float(config['training']['lr'])\n",
    "\n",
    "    #------------------------ Preprocessing ------------------------#\n",
    "    val_dir = dir + 'validation/'\n",
    "    for j in range(1,13): # out loop to inference all subjects\n",
    "        results = []\n",
    "        subject_num = j # ignore the config subject num\n",
    "        # load data and do preprocessing\n",
    "\n",
    "        # load validation data\n",
    "        print(f\"Starting to load Subject{subject_num} Data.\")\n",
    "        for file in os.listdir(val_dir):\n",
    "            sub_idx = file.find('_')\n",
    "            if file[:-4].endswith('_data') & (file[4:sub_idx] == str(subject_num)):\n",
    "                raw = creat_mne_raw_object(val_dir+file,read_events=True)\n",
    "                # filter all channels\n",
    "                input_signal,target_signal = filter_standardization(raw,window_size = 1000,\n",
    "                                    l_freq = 0,h_freq = 30)\n",
    "\n",
    "                input_tensor = ttype(input_signal.reshape(1,1,input_signal.shape[0],-1))\n",
    "                target_tensor = labeltype(target_signal.reshape(6,-1)) # should be six channels\n",
    "                # for batch of 1 only squeeze the first dimension\n",
    "                input_tensor = input_tensor.squeeze(0)\n",
    "                target_tensor = target_tensor.unsqueeze(0)\n",
    "                ###########for validation do not patch data ###########\n",
    "                # patches data \n",
    "                #patches_train = input_tensor.unfold(dimension = 1, size = kernel_size, step = step).permute(1,0,2)\n",
    "                #patches_label = target_tensor.unfold(1, kernel_size, step).permute(1,0,2)\n",
    "                #print(patches_train.shape, patches_label.shape)\n",
    "                val_x_t = input_tensor\n",
    "                val_y_t = target_tensor\n",
    "                #test_y_t = torch.cat(train_y_list, dim=0)\n",
    "                print(val_x_t.shape, val_y_t.shape)\n",
    "\n",
    "                print(\"Finished! {} data are loaded and preprocessed\".format(len(val_x_t)))\n",
    "\n",
    "\n",
    "        # -----------------------inference ----------------------------#\n",
    "        df_inf = pd.DataFrame()\n",
    "        for i in range(1,7): # There are six events 1 - 6\n",
    "            nClass = i - 1\n",
    "            if model == 'DeepSITH':\n",
    "                # make a copy of every dict don't want to change them\n",
    "                layer_params_l = [sith_params1.copy(), \n",
    "                                  sith_params2.copy(),sith_params3.copy()]\n",
    "                \n",
    "                # j is the current subject\n",
    "                file = f'Deep_isith_Subject{j}_numEvent{nClass}.pth'\n",
    "                PATH = 'saved_NNs/' + file\n",
    "                model1 = DeepSITH_Tracker(out=2,\n",
    "                                         layer_params=layer_params_l, dropout=0.1).double()\n",
    "                \n",
    "            elif model == 'LSTM':\n",
    "                file = f'LSTM_Subject{j}_numEvent{nClass}.pth'\n",
    "                PATH = 'saved_NNs/' + file\n",
    "                # number of parameters \n",
    "                hidden_size = 25\n",
    "                model1 = LSTM_EEG(in_features = 32, hidden_dim = hidden_size, \n",
    "                                  out_feuture = 2,num_layers =3, dropout=0.1).double()\n",
    "            else:\n",
    "                print('No model found. Needs to be either DeepSITH or LSTM')\n",
    "            \n",
    "            \n",
    "            model1.load_state_dict(torch.load(PATH))    \n",
    "            model1.eval()\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model1.to(device)\n",
    "\n",
    "            val_y_t_nClass = val_y_t[:,nClass,:]\n",
    "            # create dataloader class\n",
    "            val_dataset = EEGDataset(val_x_t ,val_y_t)\n",
    "\n",
    "            val_loader = DataLoader(dataset= val_dataset, batch_size=1, \n",
    "                                 shuffle=False)\n",
    "            y_pred, y_gt = inference(model1, val_loader)\n",
    "            df_inf[str(nClass)] = y_pred\n",
    "\n",
    "\n",
    "        # save as dataframes\n",
    "        # rename\n",
    "        colName = ['HandStart', 'FirstDigitTouch', 'BothStartLoadPhase',\n",
    "                  'LiftOff', 'Replace', 'BothReleased']\n",
    "        df_inf.columns = colName\n",
    "        if not os.path.exists('inference'):\n",
    "            os.makedirs('inference')\n",
    " \n",
    "        df_inf.to_csv('inference/' + f'{model}_Subject{j}' + '_inference' + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load Subject1 Data.\n",
      "torch.Size([1, 32, 117333]) torch.Size([1, 6, 117333])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject2 Data.\n",
      "torch.Size([1, 32, 149945]) torch.Size([1, 6, 149945])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject3 Data.\n",
      "torch.Size([1, 32, 114946]) torch.Size([1, 6, 114946])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject4 Data.\n",
      "torch.Size([1, 32, 121920]) torch.Size([1, 6, 121920])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject5 Data.\n",
      "torch.Size([1, 32, 129504]) torch.Size([1, 6, 129504])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject6 Data.\n",
      "torch.Size([1, 32, 135837]) torch.Size([1, 6, 135837])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject7 Data.\n",
      "torch.Size([1, 32, 140424]) torch.Size([1, 6, 140424])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject8 Data.\n",
      "torch.Size([1, 32, 124095]) torch.Size([1, 6, 124095])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject9 Data.\n",
      "torch.Size([1, 32, 127494]) torch.Size([1, 6, 127494])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject10 Data.\n",
      "torch.Size([1, 32, 126733]) torch.Size([1, 6, 126733])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject11 Data.\n",
      "torch.Size([1, 32, 134289]) torch.Size([1, 6, 134289])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject12 Data.\n",
      "torch.Size([1, 32, 154678]) torch.Size([1, 6, 154678])\n",
      "Finished! 1 data are loaded and preprocessed\n"
     ]
    }
   ],
   "source": [
    "inference_all(model = 'DeepSITH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make finale result table\n",
    "def makeTable(model = 'DeepSITH'):\n",
    "    colName = ['HandStart', 'FirstDigitTouch', 'BothStartLoadPhase',\n",
    "                  'LiftOff', 'Replace', 'BothReleased']\n",
    "    final_result = pd.DataFrame(columns=['Subject','Event','AUC', 'Precision', 'Recall', 'F1'])\n",
    "\n",
    "    for j in range(1,13): # out loop evaluate all subjects\n",
    "        # load data\n",
    "        if model == 'DeepSITH':\n",
    "            inf = f'inference/DeepSITH_Subject{j}_inference.csv'\n",
    "        elif model == 'LSTM':\n",
    "            inf = f'inference/LSTM_Subject{j}_inference.csv'\n",
    "        else:\n",
    "            print('No model found. Needs to be either DeepSITH or LSTM')\n",
    "        gt = f'grasp-and-lift-eeg-detection/validation/subj{j}_series8_events.csv'\n",
    "        df_inf = pd.read_csv(inf)\n",
    "        df_gt = pd.read_csv(gt)\n",
    "        df_inf = df_inf.drop(['Unnamed: 0'], axis = 1)\n",
    "        #df_gt = df_gt.drop(['Unnamed: 0'], axis = 1)\n",
    "        # make binary table\n",
    "        threshold = .3\n",
    "        df_inf_binary = df_inf.copy()\n",
    "        df_inf_binary[df_inf_binary > threshold] = 1\n",
    "        df_inf_binary[df_inf_binary <= threshold] = 0\n",
    "\n",
    "        for i in colName:\n",
    "            # evaluation metrics, i is each event\n",
    "            #print(df_inf_binary[i])\n",
    "            auc = roc_auc_score(y_true = df_gt[i] ,y_score = df_inf[i])\n",
    "            p = precision_score(y_true = df_gt[i] ,y_pred = df_inf_binary[i])\n",
    "            r = recall_score(y_true = df_gt[i] ,y_pred = df_inf_binary[i])\n",
    "            f1 = f1_score(y_true = df_gt[i]  ,y_pred = df_inf_binary[i])\n",
    "\n",
    "            # j is again subject, i is event\n",
    "            final_result = final_result.append({'Subject':j,'Event':i,'AUC':auc, \n",
    "                                                'Precision':p, 'Recall':r, 'F1':f1}, ignore_index=True)\n",
    "            print(f'AUC:{auc}, Precision:{p}, Recall:{r}, F1:{f1}')\n",
    "            \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:0.9421479090330811, Precision:0.8016894609814964, Recall:0.3907843137254902, F1:0.5254416029528078\n",
      "AUC:0.9835303237330323, Precision:0.7523031461845994, Recall:0.8486274509803922, F1:0.7975674928591173\n",
      "AUC:0.9888792485800286, Precision:0.8151408450704225, Recall:0.8170588235294117, F1:0.8160987074030552\n",
      "AUC:0.9700617081096871, Precision:0.6173617021276596, Recall:0.7111764705882353, F1:0.6609567198177676\n",
      "AUC:0.984189685568346, Precision:0.6954342984409799, Recall:0.7347058823529412, F1:0.7145308924485126\n",
      "AUC:0.9687344762288116, Precision:0.6981062012625325, Recall:0.7372549019607844, F1:0.7171466717528132\n",
      "AUC:0.9543428330081041, Precision:0.5344166102459942, Recall:0.46431372549019606, F1:0.4969048368481796\n",
      "AUC:0.9767026023084852, Precision:0.5454980079681275, Recall:0.6711764705882353, F1:0.6018461538461538\n",
      "AUC:0.9827109601270864, Precision:0.651024208566108, Recall:0.6854901960784314, F1:0.6678127984718243\n",
      "AUC:0.9183673636253495, Precision:0.39921512665001785, Recall:0.4388235294117647, F1:0.41808331776573887\n",
      "AUC:0.9512816323602176, Precision:0.42901310907741774, Recall:0.6801960784313725, F1:0.526164113453663\n",
      "AUC:0.9333940378457297, Precision:0.3256545565252689, Recall:0.6292156862745099, F1:0.4291828273371673\n",
      "AUC:0.8870390543195411, Precision:0.6937716262975778, Recall:0.23588235294117646, F1:0.3520632133450395\n",
      "AUC:0.905710784759983, Precision:0.5881038815973192, Recall:0.41294117647058826, F1:0.4851975578850364\n",
      "AUC:0.9175880457239067, Precision:0.587989170563623, Recall:0.4684313725490196, F1:0.5214449416130089\n",
      "AUC:0.9297729298736592, Precision:0.5565217391304348, Recall:0.4015686274509804, F1:0.46651480637813214\n",
      "AUC:0.9224669260672606, Precision:0.45046187284912154, Recall:0.48764705882352943, F1:0.46831748422935693\n",
      "AUC:0.915273214942988, Precision:0.4652990797546012, Recall:0.4758823529411765, F1:0.4705312136487011\n",
      "AUC:0.9552103688933201, Precision:0.7943118334179786, Recall:0.6133333333333333, F1:0.6921885372870104\n",
      "AUC:0.9300504546965166, Precision:0.7272727272727273, Recall:0.4454901960784314, F1:0.5525291828793775\n",
      "AUC:0.9301652852889144, Precision:0.7039297046619478, Recall:0.5654901960784313, F1:0.6271610307709035\n",
      "AUC:0.9477200351806532, Precision:0.5468689225982108, Recall:0.5513725490196079, F1:0.549111501659832\n",
      "AUC:0.9543194020631707, Precision:0.5402397260273972, Recall:0.4949019607843137, F1:0.5165779778960294\n",
      "AUC:0.9086533648213608, Precision:0.3286070128377084, Recall:0.3362745098039216, F1:0.3323965500532997\n",
      "AUC:0.739762759031139, Precision:0.35294117647058826, Recall:0.13294117647058823, F1:0.1931348810710725\n",
      "AUC:0.8616226371259734, Precision:0.4965034965034965, Recall:0.1392156862745098, F1:0.21745788667687593\n",
      "AUC:0.9178900826592171, Precision:0.4987684729064039, Recall:0.1588235294117647, F1:0.2409280190362879\n",
      "AUC:0.8680502880873259, Precision:0.29234012649332397, Recall:0.0815686274509804, F1:0.12754867392304156\n",
      "AUC:0.7978708600253065, Precision:0.37580794090489383, Recall:0.1596078431372549, F1:0.22405725295898707\n",
      "AUC:0.8977862211731419, Precision:0.38152731663145184, Recall:0.24784313725490195, F1:0.3004873410198502\n",
      "AUC:0.9107347770640262, Precision:0.6274937655860349, Recall:0.3947058823529412, F1:0.4845931632161771\n",
      "AUC:0.8929009025304057, Precision:0.6573799644339063, Recall:0.4349019607843137, F1:0.5234835968845881\n",
      "AUC:0.923232595240227, Precision:0.5731563421828909, Recall:0.38098039215686275, F1:0.45771495877502943\n",
      "AUC:0.9085853247959118, Precision:0.4868686868686869, Recall:0.23627450980392156, F1:0.31815181518151814\n",
      "AUC:0.9486841281561081, Precision:0.5188301282051282, Recall:0.5078431372549019, F1:0.5132778438367023\n",
      "AUC:0.8768657746798054, Precision:0.4079765825100622, Recall:0.4372549019607843, F1:0.4221086503880371\n",
      "AUC:0.8947516707903936, Precision:0.5758447160316319, Recall:0.31411764705882356, F1:0.40649581324536926\n",
      "AUC:0.9541001451273661, Precision:0.5693207126948775, Recall:0.40098039215686276, F1:0.470547630004602\n",
      "AUC:0.9563506902314737, Precision:0.44356435643564357, Recall:0.2968853545394301, F1:0.3556967050416832\n",
      "AUC:0.891906328225476, Precision:0.41496920890573186, Recall:0.34352941176470586, F1:0.37588500321819346\n",
      "AUC:0.9085618451808615, Precision:0.47919655667144906, Recall:0.39294117647058824, F1:0.43180349062702006\n",
      "AUC:0.8998888202084062, Precision:0.6108126259234385, Recall:0.3566666666666667, F1:0.450358999752414\n",
      "AUC:0.8015604511311647, Precision:0.5824782951854776, Recall:0.14470588235294118, F1:0.23182032354327003\n",
      "AUC:0.8630984478668985, Precision:0.514187866927593, Recall:0.41215686274509805, F1:0.457553330430997\n",
      "AUC:0.9110611848083913, Precision:0.5584524810765349, Recall:0.3905882352941176, F1:0.45967462789892694\n",
      "AUC:0.8892030823506343, Precision:0.4339705559217754, Recall:0.3872549019607843, F1:0.40928401201947984\n",
      "AUC:0.9646682567812619, Precision:0.6233445170404379, Recall:0.692156862745098, F1:0.6559509430456193\n",
      "AUC:0.9359556250921732, Precision:0.5328813559322034, Recall:0.6164705882352941, F1:0.5716363636363636\n",
      "AUC:0.8925946036698582, Precision:0.6646276595744681, Recall:0.49, F1:0.5641083521444696\n",
      "AUC:0.9421854573160866, Precision:0.595264116575592, Recall:0.6407843137254902, F1:0.6171860245514637\n",
      "AUC:0.973647412230575, Precision:0.7061412701739678, Recall:0.6605882352941177, F1:0.6826056123999595\n",
      "AUC:0.9297186008413201, Precision:0.5326858423608517, Recall:0.5592156862745098, F1:0.5456284675722212\n",
      "AUC:0.8844788543716259, Precision:0.5358948432760364, Recall:0.41568627450980394, F1:0.46819787985865724\n",
      "AUC:0.916788513598161, Precision:0.5600552231937413, Recall:0.4772549019607843, F1:0.5153504128731738\n",
      "AUC:0.9129433543496241, Precision:0.6058563792702766, Recall:0.5111764705882353, F1:0.5545038817398703\n",
      "AUC:0.9071784553437269, Precision:0.5488703339882122, Recall:0.43823529411764706, F1:0.487352812908853\n",
      "AUC:0.9401714962867245, Precision:0.6140417457305503, Recall:0.6345098039215686, F1:0.6241080038572806\n",
      "AUC:0.9335555898384774, Precision:0.35889423076923077, Recall:0.5854901960784313, F1:0.4450074515648286\n",
      "AUC:0.9002298025094132, Precision:0.6280023432923257, Recall:0.4203921568627451, F1:0.5036410617805966\n",
      "AUC:0.909668364316121, Precision:0.4103762561346109, Recall:0.34431372549019607, F1:0.3744535664783026\n",
      "AUC:0.87583389680327, Precision:0.5183068783068783, Recall:0.4801960784313726, F1:0.49852417302798985\n",
      "AUC:0.9149133136600744, Precision:0.35823721810982956, Recall:0.4080392156862745, F1:0.38151984599871663\n",
      "AUC:0.870750236885038, Precision:0.4587950138504155, Recall:0.25980392156862747, F1:0.33174762143214825\n",
      "AUC:0.8989808213805612, Precision:0.4149453219927096, Recall:0.26784313725490194, F1:0.32554814108674923\n",
      "AUC:0.8820253272337429, Precision:0.4211133069828722, Recall:0.5013725490196078, F1:0.45775152166129607\n",
      "AUC:0.8869088380771811, Precision:0.43620234050585127, Recall:0.4531372549019608, F1:0.44450855933833433\n",
      "AUC:0.8981576888600845, Precision:0.46169114728066696, Recall:0.2280392156862745, F1:0.30528940805880034\n",
      "AUC:0.8758613526839824, Precision:0.5282258064516129, Recall:0.38529411764705884, F1:0.445578231292517\n",
      "AUC:0.940400985622558, Precision:0.5891777509068924, Recall:0.382156862745098, F1:0.46360608943862985\n",
      "AUC:0.8719133462795592, Precision:0.4742238678439191, Recall:0.3264705882352941, F1:0.3867146672860295\n",
      "AUC:0.9433306447236265, Precision:0.464793082149475, Recall:0.5901960784313726, F1:0.5200414651002073\n",
      "AUC:0.8545321871545019, Precision:0.36362003950439936, Recall:0.39705882352941174, F1:0.37960446152404165\n"
     ]
    }
   ],
   "source": [
    "final_result_SITH = makeTable(model = 'DeepSITH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_SITH.to_csv(f'DeepSITH_final_result_padding.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject      6.500000\n",
       "AUC          0.914308\n",
       "Precision    0.534818\n",
       "Recall       0.447440\n",
       "F1           0.472611\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_SITH.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AUC  Precision  Recall     F1\n",
       "Subject                                 \n",
       "1        0.973      0.730   0.707  0.705\n",
       "2        0.953      0.481   0.595  0.523\n",
       "3        0.913      0.557   0.414  0.461\n",
       "4        0.938      0.607   0.501  0.545\n",
       "5        0.847      0.400   0.153  0.217\n",
       "6        0.910      0.545   0.399  0.453\n",
       "7        0.918      0.516   0.351  0.415\n",
       "8        0.894      0.541   0.441  0.464\n",
       "9        0.923      0.599   0.541  0.566\n",
       "10       0.917      0.528   0.489  0.498\n",
       "11       0.888      0.435   0.395  0.407\n",
       "12       0.897      0.480   0.385  0.417"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_SITH.groupby('Subject').aggregate({'AUC':'mean','Precision':'mean','Recall':'mean',\n",
    "                                 'F1':'mean'}).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load Subject1 Data.\n",
      "torch.Size([1, 32, 117333]) torch.Size([1, 6, 117333])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject2 Data.\n",
      "torch.Size([1, 32, 149945]) torch.Size([1, 6, 149945])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject3 Data.\n",
      "torch.Size([1, 32, 114946]) torch.Size([1, 6, 114946])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject4 Data.\n",
      "torch.Size([1, 32, 121920]) torch.Size([1, 6, 121920])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject5 Data.\n",
      "torch.Size([1, 32, 129504]) torch.Size([1, 6, 129504])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject6 Data.\n",
      "torch.Size([1, 32, 135837]) torch.Size([1, 6, 135837])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject7 Data.\n",
      "torch.Size([1, 32, 140424]) torch.Size([1, 6, 140424])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject8 Data.\n",
      "torch.Size([1, 32, 124095]) torch.Size([1, 6, 124095])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject9 Data.\n",
      "torch.Size([1, 32, 127494]) torch.Size([1, 6, 127494])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject10 Data.\n",
      "torch.Size([1, 32, 126733]) torch.Size([1, 6, 126733])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject11 Data.\n",
      "torch.Size([1, 32, 134289]) torch.Size([1, 6, 134289])\n",
      "Finished! 1 data are loaded and preprocessed\n",
      "Starting to load Subject12 Data.\n",
      "torch.Size([1, 32, 154678]) torch.Size([1, 6, 154678])\n",
      "Finished! 1 data are loaded and preprocessed\n"
     ]
    }
   ],
   "source": [
    "inference_all(model = 'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:0.8208903186875063, Precision:0.47709593777009507, Recall:0.2164705882352941, F1:0.2978149446992177\n",
      "AUC:0.9591796285843021, Precision:0.49693080357142855, Recall:0.6984313725490197, F1:0.5806977502445386\n",
      "AUC:0.9586396367640639, Precision:0.4399951016409503, Recall:0.7045098039215686, F1:0.5416855118347655\n",
      "AUC:0.9591266767682008, Precision:0.4633356465417534, Recall:0.7854901960784314, F1:0.5828604684999273\n",
      "AUC:0.9362693821659178, Precision:0.5092918131592165, Recall:0.5964705882352941, F1:0.5494445949607153\n",
      "AUC:0.8989677427019386, Precision:0.5679433368310598, Recall:0.4245098039215686, F1:0.4858617594254937\n",
      "AUC:0.871567030070684, Precision:0.2507345739471107, Recall:0.1003921568627451, F1:0.14337720526463174\n",
      "AUC:0.9178437789144447, Precision:0.3330906443392792, Recall:0.17941176470588235, F1:0.233210144004078\n",
      "AUC:0.9057617737419107, Precision:0.3948509485094851, Recall:0.28568627450980394, F1:0.33151308304891924\n",
      "AUC:0.9270093115087864, Precision:0.38433962264150945, Recall:0.39941176470588236, F1:0.39173076923076927\n",
      "AUC:0.9273886784994644, Precision:0.35908838243468594, Recall:0.5066666666666667, F1:0.4202992843201041\n",
      "AUC:0.8987803554712643, Precision:0.0, Recall:0.0, F1:0.0\n",
      "AUC:0.7848862203876872, Precision:0.285264483627204, Recall:0.1776470588235294, F1:0.2189463508941518\n",
      "AUC:0.8632008912298967, Precision:0.33654893418391163, Recall:0.42411764705882354, F1:0.37529279083890005\n",
      "AUC:0.864035892673986, Precision:0.41972076788830714, Recall:0.3772549019607843, F1:0.39735646427096244\n",
      "AUC:0.8767953976922416, Precision:0.33633885510589223, Recall:0.31450980392156863, F1:0.325058263248556\n",
      "AUC:0.8098747283630237, Precision:0.3252032520325203, Recall:0.07058823529411765, F1:0.11599806669888835\n",
      "AUC:0.8218964268335742, Precision:0.36028334147532975, Recall:0.28921568627450983, F1:0.32086143136828366\n",
      "AUC:0.8864615261958234, Precision:0.5010491956166939, Recall:0.42137254901960786, F1:0.45776973053573333\n",
      "AUC:0.9446923656639509, Precision:0.51140502204332, Recall:0.5231372549019608, F1:0.5172046137443056\n",
      "AUC:0.9527289109103666, Precision:0.4670506295204929, Recall:0.6837254901960784, F1:0.5549896546235875\n",
      "AUC:0.9558259480816808, Precision:0.52660406885759, Recall:0.527843137254902, F1:0.527222875048962\n",
      "AUC:0.820784689701938, Precision:0.27771984706291275, Recall:0.15666666666666668, F1:0.2003259370690736\n",
      "AUC:0.87372029869986, Precision:0.23472065991751032, Recall:0.24549019607843137, F1:0.23998466551658038\n",
      "AUC:0.5811168388129504, Precision:0.12776637006616473, Recall:0.10980392156862745, F1:0.1181060845723927\n",
      "AUC:0.8004300315669819, Precision:0.41614195764167144, Recall:0.14254901960784314, F1:0.2123557762523733\n",
      "AUC:0.8487217547383572, Precision:0.39430680021085923, Recall:0.14666666666666667, F1:0.21380591682149494\n",
      "AUC:0.7848778978167905, Precision:0.1907839280696825, Recall:0.1331372549019608, F1:0.15683104284559418\n",
      "AUC:0.7079163396170982, Precision:0.23843843843843843, Recall:0.07784313725490197, F1:0.1173688100517369\n",
      "AUC:0.8129963335773203, Precision:0.171242774566474, Recall:0.09294117647058824, F1:0.1204880528723945\n",
      "AUC:0.7687237346884264, Precision:0.28134196586227195, Recall:0.09372549019607843, F1:0.14060891307545229\n",
      "AUC:0.8624434851768713, Precision:0.4412840308817554, Recall:0.21294117647058824, F1:0.287263589472292\n",
      "AUC:0.8850372661054142, Precision:0.4620601949978805, Recall:0.21372549019607842, F1:0.2922643786030299\n",
      "AUC:0.8276895719545916, Precision:0.34210526315789475, Recall:0.2192156862745098, F1:0.26720841300191206\n",
      "AUC:0.896908635762833, Precision:0.3399588759424263, Recall:0.38901960784313727, F1:0.3628383321141185\n",
      "AUC:0.8079507114042906, Precision:0.3621599675192854, Recall:0.17490196078431372, F1:0.2358852307285469\n",
      "AUC:0.8137949951344079, Precision:0.28818827708703376, Recall:0.12725490196078432, F1:0.176550598476605\n",
      "AUC:0.9559656577300898, Precision:0.4541499330655957, Recall:0.532156862745098, F1:0.4900686168291802\n",
      "AUC:0.8920777116507916, Precision:0.27609308885754585, Recall:0.17296222664015903, F1:0.21268504685590112\n",
      "AUC:0.8936029245134844, Precision:0.40034071550255534, Recall:0.09215686274509804, F1:0.14982467325470197\n",
      "AUC:0.8663852360724965, Precision:0.3809995051954478, Recall:0.15098039215686274, F1:0.21626176098862518\n",
      "AUC:0.8928518715576443, Precision:0.4806013579049467, Recall:0.19431372549019607, F1:0.27673834124546215\n",
      "AUC:0.7843411496116578, Precision:0.24139106716672348, Recall:0.1388235294117647, F1:0.17627287439312833\n",
      "AUC:0.8595596997402264, Precision:0.2392772711921648, Recall:0.27784313725490195, F1:0.2571221193975685\n",
      "AUC:0.886096809142582, Precision:0.3231644260599793, Recall:0.36764705882352944, F1:0.3439735828288387\n",
      "AUC:0.8757652957901509, Precision:0.3228060368921185, Recall:0.45294117647058824, F1:0.3769582245430809\n",
      "AUC:0.9070470056000046, Precision:0.4268148148148148, Recall:0.5649019607843138, F1:0.48624472573839667\n",
      "AUC:0.9292511548928155, Precision:0.4118478388882346, Recall:0.6856862745098039, F1:0.5146052534765654\n",
      "AUC:0.8157924087653918, Precision:0.273305954825462, Recall:0.26098039215686275, F1:0.26700100300902707\n",
      "AUC:0.9150648083800084, Precision:0.49926113573991976, Recall:0.46372549019607845, F1:0.48083765375622645\n",
      "AUC:0.898575095152364, Precision:0.5194060953373274, Recall:0.39098039215686275, F1:0.4461349144199575\n",
      "AUC:0.9156741215367792, Precision:0.4144777031154551, Recall:0.266078431372549, F1:0.3240983998089324\n",
      "AUC:0.8225338676412114, Precision:0.2759493670886076, Recall:0.21372549019607842, F1:0.24088397790055247\n",
      "AUC:0.8939402802969644, Precision:0.3832639852057328, Recall:0.32509803921568625, F1:0.3517929132187566\n",
      "AUC:0.8914512654025295, Precision:0.46543040293040294, Recall:0.39862745098039215, F1:0.4294465568229827\n",
      "AUC:0.9397844786381664, Precision:0.3231960498260577, Recall:0.5647058823529412, F1:0.4111055599172079\n",
      "AUC:0.9588117517772444, Precision:0.3904233171408744, Recall:0.5515686274509803, F1:0.45721251523770823\n",
      "AUC:0.9296057378004517, Precision:0.3418416801292407, Recall:0.20745098039215687, F1:0.2582062233068944\n",
      "AUC:0.855199114726831, Precision:0.0, Recall:0.0, F1:0.0\n",
      "AUC:0.843846806602246, Precision:0.16339869281045752, Recall:0.004901960784313725, F1:0.009518370454978107\n",
      "AUC:0.8423507920224496, Precision:0.41918735891647857, Recall:0.36411764705882355, F1:0.3897166841552991\n",
      "AUC:0.8486104580930902, Precision:0.2524226320725227, Recall:0.31666666666666665, F1:0.2809184205948861\n",
      "AUC:0.8818454919141876, Precision:0.33765790372140664, Recall:0.19392156862745097, F1:0.24635695603437538\n",
      "AUC:0.8825123200709585, Precision:0.47732389835960115, Recall:0.2909803921568627, F1:0.36155439152150076\n",
      "AUC:0.8740752741195867, Precision:0.3150519449142305, Recall:0.2556862745098039, F1:0.2822816322112782\n",
      "AUC:0.8777147404797866, Precision:0.2684172137126185, Recall:0.14431372549019608, F1:0.18770721754654426\n",
      "AUC:0.7867142620061303, Precision:0.234375, Recall:0.047058823529411764, F1:0.07838014369693011\n",
      "AUC:0.8056433170548568, Precision:0.19946984758117958, Recall:0.059019607843137256, F1:0.09108791042517779\n",
      "AUC:0.7908633583265233, Precision:0.25, Recall:0.10941176470588235, F1:0.15220949263502456\n",
      "AUC:0.8496465048467072, Precision:0.3376539209332469, Recall:0.20431372549019608, F1:0.2545809919374542\n",
      "AUC:0.8615481541665323, Precision:0.40109333873253694, Recall:0.3884313725490196, F1:0.39466082279111464\n",
      "AUC:0.8314447547728393, Precision:0.29585953878406707, Recall:0.22137254901960784, F1:0.253252579632122\n"
     ]
    }
   ],
   "source": [
    "final_result_LSTM = makeTable(model = 'LSTM')\n",
    "final_result_LSTM.to_csv(f'LSTM_final_result_padding.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject      6.500000\n",
       "AUC          0.866543\n",
       "Precision    0.348755\n",
       "Recall       0.293282\n",
       "F1           0.300844\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_LSTM.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AUC  Precision  Recall     F1\n",
       "Subject                                 \n",
       "1        0.922      0.492   0.571  0.506\n",
       "2        0.908      0.287   0.245  0.253\n",
       "3        0.837      0.344   0.276  0.292\n",
       "4        0.906      0.420   0.426  0.416\n",
       "5        0.756      0.256   0.117  0.156\n",
       "6        0.841      0.371   0.217  0.264\n",
       "7        0.886      0.380   0.212  0.254\n",
       "8        0.874      0.328   0.415  0.359\n",
       "9        0.877      0.394   0.320  0.352\n",
       "10       0.903      0.281   0.288  0.261\n",
       "11       0.868      0.345   0.261  0.291\n",
       "12       0.821      0.286   0.172  0.204"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_LSTM.groupby('Subject').aggregate({'AUC':'mean','Precision':'mean','Recall':'mean',\n",
    "                                 'F1':'mean'}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.4.0 Py3.7",
   "language": "python",
   "name": "pytorch140_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
